import fiona.transform
import numpy as np
import rasterio
import shapely.geometry
from affine import Affine
from pystac_client import Client
from rasterio.enums import Resampling
from tqdm import tqdm
import pandas as pd

CATALOG = Client.open("https://planetarycomputer.microsoft.com/api/stac/v1")
np.random.seed(1337)


class InTheOceanProbablyError(Exception):
    pass


def random_crop_to_file(url, output_fn):
    """Reads a random 256 x 256 meter crop from an input GeoTIFF and saves the result as
    a 256 x 256 pixel GeoTIFF (i.e. 1m/px resolution) resampling with bilinear
    interpolation as necessary. It is necessary to resample because sometimes NAIP is
    0.6m/px resolution.

    Args:
        url: input URL (preferably a Cloud Optimized GeoTIFF)
        output_fn: local file in which to save the resulting crop

    Returns:
        lat, lon centroid of the resulting crop
    """
    with rasterio.open(url) as f:
        xmin, ymin, xmax, ymax = f.bounds
        crs = f.crs.to_string()
        width = xmax - xmin
        height = ymax - ymin

        xoffset = np.random.rand() * width - 256
        yoffset = np.random.rand() * height - 256

        window = f.window(
            xmin + xoffset, ymin + yoffset, xmin + xoffset + 256, ymin + yoffset + 256
        )
        data = f.read(
            window=window, out_shape=(256, 256), resampling=Resampling.bilinear
        )

        dst_transform = Affine(
            1.0, 0.0, xmin + xoffset, 0.0, -1.0, ymin + yoffset + 256
        )

        profile = f.profile.copy()
        profile["transform"] = dst_transform
        profile["height"] = 256
        profile["width"] = 256
        profile["photometric"] = "RGB"
        profile["compress"] = "deflate"
        profile["predictor"] = 2
        profile["blockxsize"] = 256
        profile["blockysize"] = 256

        with rasterio.open(output_fn, "w", **profile) as g:
            g.write(data)

    lats, lons = fiona.transform.transform(
        crs, "epsg:4326", [xmin + xoffset + 128], [ymin + yoffset + 128]
    )
    return lats[0], lons[0]


def get_naip_around_point_time(lat, lon, date_range, output_fn):
    """Samples a random crop of NAIP imagery from around a given lat, lon point and
    writes the result to file as a GeoTIFF.

    NAIP imagery is distributed in overlapping "tiles". For a given (lat, lon,
    date_range) this method will look up the intersecting tiles using the Planetary
    Computer API, choose a resulting tile at random, then sample a random 256x256 meter
    window from the chosen tile.

    Args:
        lat: latitude of point to search
        lon: longitude of point to search
        date_range: date range to search over, expected format as
            "2018-01-01/2020-01-01"
        output_fn: path to save the random crop to

    Returns:
        dictionary with "lat", "lon", and "path" keys that describe the centroid and
            output file name of the sampled crop
    """
    point_geom = shapely.geometry.mapping(shapely.geometry.Point(lon, lat))

    search = CATALOG.search(
        collections=["naip"],
        intersects=point_geom,
        datetime=date_range,
    )

    items = [item.to_dict() for item in search.get_items()]

    if len(items) == 0:
        raise InTheOceanProbablyError()

    item = np.random.choice(items)
    url = item["assets"]["image"]["href"]

    lat, lon = random_crop_to_file(url, output_fn)

    return {
        "lat": lat,
        "lon": lon,
        "path": output_fn,
    }


def main():
    USA_BOUNDS = [-124.85, 24.40, -66.89, 49.38]  # generated by Copilot
    minx, miny, maxx, maxy = USA_BOUNDS
    width = maxx - minx
    height = maxy - miny

    date_range = "2018-01-01/2020-01-01"

    rows = []
    for i in tqdm(range(25)):
        while True:
            lon = np.random.rand() * width + minx
            lat = np.random.rand() * height + miny
            row = None
            try:
                row = get_naip_around_point_time(
                    lat, lon, date_range=date_range, output_fn=f"data/sample_{i}.tif"
                )
            except InTheOceanProbablyError:
                pass

            if row is not None:
                break

        rows.append(row)

    df = pd.DataFrame(rows)
    df.to_csv("index.csv", index=False)


if __name__ == "__main__":
    main()
